{
  "training": {
    "batch_size": 16,
    "epochs": 2,
    "learning_rate": 1e-5,
    "validation_split_percentage": 0
  },
  "model": {
    "bert": {
      "hidden_size": 768,
      "num_attention_heads": 12,
      "num_hidden_layers": 6,
      "type_vocab_size": 1,
      "max_position_embeddings": 256
    },
    "distilbert": {
      "dropout": 0.4,
      "attention_dropout": 0.3,
      "qa_dropout": 0.3,
      "max_position_embeddings": 256
    }
  },
  "dataloader": {
    "num_workers": 4,
    "prefetch_factor": 2
  }
}